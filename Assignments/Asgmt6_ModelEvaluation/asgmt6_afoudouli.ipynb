{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Assignment 6 \n",
    "\n",
    "In this assignment, the breast cancer dataset of sklearn library is used.     \n",
    "I will try to classify the patients to be having malignant or beneign tumors.\n",
    "\n",
    "Goal of the assignment is to calculate a model's accuracy using the leave-one-out cross validation technique.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Brief dataset description  \n",
    "\n",
    "The dataset consists of 569 entries of 30 numeric predictive variables and the outcome.  \n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.   \n",
    "\n",
    "#### Attribute information  \n",
    "* radius (mean of distances from center to points on the perimeter)\n",
    "* texture (standard deviation of gray-scale values)\n",
    "* perimeter\n",
    "* area\n",
    "* smoothness (local variation in radius lengths)\n",
    "* compactness (perimeter^2 / area - 1.0)\n",
    "* concavity (severity of concave portions of the contour)\n",
    "* concave points (number of concave portions of the contour)\n",
    "* symmetry\n",
    "* fractal dimension (“coastline approximation” - 1)\n",
    "\n",
    "The mean, standard error, and “worst” or largest (mean of the three worst/largest values) of these features were computed for each image, resulting in 30 features. For instance, field 0 is Mean Radius, field 10 is Radius SE, field 20 is Worst Radius.  \n",
    "\n",
    "\n",
    "As found on [sklearn documentation](https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset)\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancerDF = load_breast_cancer(as_frame=True)['frame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_vars = ['mean radius', 'mean texture', 'mean smoothness', 'mean compactness',\n",
    "       'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error',\n",
    "       'smoothness error', 'compactness error', 'symmetry error', 'worst symmetry', \n",
    "       'target']\n",
    "\n",
    "cancerDF = cancerDF[selected_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   mean radius  mean texture  mean smoothness  mean compactness  \\\n",
       "0        17.99         10.38          0.11840           0.27760   \n",
       "1        20.57         17.77          0.08474           0.07864   \n",
       "2        19.69         21.25          0.10960           0.15990   \n",
       "3        11.42         20.38          0.14250           0.28390   \n",
       "4        20.29         14.34          0.10030           0.13280   \n",
       "\n",
       "   mean symmetry  mean fractal dimension  radius error  texture error  \\\n",
       "0         0.2419                 0.07871        1.0950         0.9053   \n",
       "1         0.1812                 0.05667        0.5435         0.7339   \n",
       "2         0.2069                 0.05999        0.7456         0.7869   \n",
       "3         0.2597                 0.09744        0.4956         1.1560   \n",
       "4         0.1809                 0.05883        0.7572         0.7813   \n",
       "\n",
       "   smoothness error  compactness error  symmetry error  worst symmetry  target  \n",
       "0          0.006399            0.04904         0.03003          0.4601       0  \n",
       "1          0.005225            0.01308         0.01389          0.2750       0  \n",
       "2          0.006150            0.04006         0.02250          0.3613       0  \n",
       "3          0.009110            0.07458         0.05963          0.6638       0  \n",
       "4          0.011490            0.02461         0.01756          0.2364       0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>radius error</th>\n      <th>texture error</th>\n      <th>smoothness error</th>\n      <th>compactness error</th>\n      <th>symmetry error</th>\n      <th>worst symmetry</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.2419</td>\n      <td>0.07871</td>\n      <td>1.0950</td>\n      <td>0.9053</td>\n      <td>0.006399</td>\n      <td>0.04904</td>\n      <td>0.03003</td>\n      <td>0.4601</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.1812</td>\n      <td>0.05667</td>\n      <td>0.5435</td>\n      <td>0.7339</td>\n      <td>0.005225</td>\n      <td>0.01308</td>\n      <td>0.01389</td>\n      <td>0.2750</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.2069</td>\n      <td>0.05999</td>\n      <td>0.7456</td>\n      <td>0.7869</td>\n      <td>0.006150</td>\n      <td>0.04006</td>\n      <td>0.02250</td>\n      <td>0.3613</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2597</td>\n      <td>0.09744</td>\n      <td>0.4956</td>\n      <td>1.1560</td>\n      <td>0.009110</td>\n      <td>0.07458</td>\n      <td>0.05963</td>\n      <td>0.6638</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1809</td>\n      <td>0.05883</td>\n      <td>0.7572</td>\n      <td>0.7813</td>\n      <td>0.011490</td>\n      <td>0.02461</td>\n      <td>0.01756</td>\n      <td>0.2364</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "cancerDF.head()"
   ]
  },
  {
   "source": [
    "Normalize all variables to follow N(0,1) (z-scores)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cancerDF.drop(columns = 'target')\n",
    "y = cancerDF['target'].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "source": [
    "### Leave-One-Out cross validation (LOOCV)\n",
    "\n",
    "Leave-one-out cross-validation, or LOOCV, is a configuration of k-fold cross-validation where k is set to the number of examples in the dataset.    \n",
    "The benefit of so many fit and evaluated models is a more robust estimate of model performance as each row of data is given an opportunity to represent the entirety of the test dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 381/381 [01:43<00:00,  3.68it/s]\n"
     ]
    }
   ],
   "source": [
    "y_act = []\n",
    "y_pred = []\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "# each iteration returns row indices\n",
    "for train_rows, test_rows in tqdm(cv.split(X_train), total=X_train.shape[0]):\n",
    "    X_train_cv, X_test_cv = X_train[train_rows], X_train[test_rows]\n",
    "    y_train_cv, y_test_cv = np.array(y_train)[train_rows], np.array(y_train)[test_rows]\n",
    "\n",
    "    clf = RandomForestClassifier(random_state=0)\n",
    "    clf.fit(X_train_cv, y_train_cv)\n",
    "    yhat = clf.predict(X_test_cv)\n",
    "    y_act.append(y_train_cv[0])\n",
    "    y_pred.append(yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_act, y_pred):\n",
    "    accuracy = sum([x==y for x,y in zip(y_act, y_pred)])/len(y_act)\n",
    "\n",
    "    tp = sum([x==y for x,y in zip(y_act, y_pred) if x==1])\n",
    "    tn = sum([x==y for x,y in zip(y_act, y_pred) if x==0])\n",
    "    fp = len([x for x in y_pred if x==1]) - tp\n",
    "    fn = len([x for x in y_pred if x==0]) - tn\n",
    "    tpr = tp/(tp+fn)\n",
    "    tnr = tn/(tn+fn)\n",
    "\n",
    "    confusionDF = pd.crosstab(pd.Series(y_pred, name='Predicted'), pd.Series(y_act, name='Actual'), margins=True)\n",
    "\n",
    "    print(f'Model accuracy: {accuracy*100:.2f}%')\n",
    "    print(f'True positive, true negative, false positive and false negative values are: {tp, tn, fp, fn}')\n",
    "    print(f'Model recall: {tpr:.2f}. Model specificity: {tnr:.2f}.\\n')\n",
    "\n",
    "    print('Confusion Matrix')\n",
    "    print(confusionDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metrics as predicted using LOO cross validation\n",
      "Model accuracy: 33.86%\n",
      "True positive, true negative, false positive and false negative values are: (0, 129, 251, 1)\n",
      "Model recall: 0.00. Model specificity: 0.99.\n",
      "\n",
      "Confusion Matrix\n",
      "Actual       0  1  All\n",
      "Predicted             \n",
      "0          129  1  130\n",
      "1          251  0  251\n",
      "All        380  1  381\n"
     ]
    }
   ],
   "source": [
    "print('Metrics as predicted using LOO cross validation')\n",
    "calculate_metrics(y_act, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test).tolist()\n",
    "y_act = y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metrics using actual train - test split (70-30 split)\nModel accuracy: 94.15%\nTrue positive, true negative, false positive and false negative values are: (109, 68, 7, 4)\nModel recall: 0.96. Model specificity: 0.94.\n\nConfusion Matrix\nActual      0    1  All\nPredicted              \n0          68    4   72\n1           7  109  116\nAll        75  113  188\n"
     ]
    }
   ],
   "source": [
    "print('Metrics using actual train - test split (70-30 split)')\n",
    "calculate_metrics(y_act, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}