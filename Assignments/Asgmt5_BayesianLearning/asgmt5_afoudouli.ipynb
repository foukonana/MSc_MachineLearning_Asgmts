{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Assignment 5\n",
    "\n",
    "In this assignment the 20 newsgroup dataset is used.  \n",
    "There are around 18000 posts on 20 different topicks. The data are also split in train and test subsets. The split is done based on a specific date. All messages before that date belong to the train set and the rest on the test set.  \n",
    "\n",
    "Goal of the assignment is to use the Naive Bayes classifier to classift the documents to their specific topic.  \n",
    "We are also going to be making the assumption that the data follow a multinomial distribution.  \n",
    "\n",
    "_Multinomial Naive Bayes is suitable for classification of discrete features, such as word counts in the case of text classification._"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "source": [
    "In scikit-learn official documentation of the dataset, it is [recommender](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) to remove features like header, footers and quotes (newsgroup related metadata) when working with a Naive Bayes classifier, as the classifier overfits on these features and does not learn actual topic-related features.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "X_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_topics = {i:x for i,x in enumerate(X_train.target_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The target topics of the data are: \nalt.atheism, comp.graphics, comp.os.ms-windows.misc, comp.sys.ibm.pc.hardware, comp.sys.mac.hardware, comp.windows.x, misc.forsale, rec.autos, rec.motorcycles, rec.sport.baseball, rec.sport.hockey, sci.crypt, sci.electronics, sci.med, sci.space, soc.religion.christian, talk.politics.guns, talk.politics.mideast, talk.politics.misc, talk.religion.misc. \n\nTrain data consist of 11314 entries and test data of 7532 entries.\nAlso there is approximate the same number of examples across all diferent topics.\n"
     ]
    }
   ],
   "source": [
    "print(f'The target topics of the data are: \\n{\", \".join(X_train.target_names)}. \\n')\n",
    "print(f'Train data consist of {X_train.filenames.shape[0]} entries and test data of {X_test.filenames.shape[0]} entries.')\n",
    "#Counter(X_train.target)\n",
    "print('Also there is approximate the same number of examples across all diferent topics.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('count_vectorizer', CountVectorizer()), \n",
    "                     ('tfidf_vectorizer', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count_vectorizer', CountVectorizer()),\n",
       "                ('tfidf_vectorizer', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "text_clf.fit(X_train.data, X_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_clf.predict(X_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'                          precision    recall  f1-score   support\\n\\n             alt.atheism       0.81      0.07      0.13       319\\n           comp.graphics       0.72      0.62      0.67       389\\n comp.os.ms-windows.misc       0.70      0.50      0.59       394\\ncomp.sys.ibm.pc.hardware       0.55      0.75      0.64       392\\n   comp.sys.mac.hardware       0.81      0.61      0.69       385\\n          comp.windows.x       0.83      0.74      0.78       395\\n            misc.forsale       0.86      0.69      0.77       390\\n               rec.autos       0.82      0.68      0.74       396\\n         rec.motorcycles       0.89      0.63      0.73       398\\n      rec.sport.baseball       0.95      0.69      0.80       397\\n        rec.sport.hockey       0.59      0.90      0.71       399\\n               sci.crypt       0.47      0.80      0.59       396\\n         sci.electronics       0.77      0.43      0.55       393\\n                 sci.med       0.86      0.63      0.73       396\\n               sci.space       0.84      0.63      0.72       394\\n  soc.religion.christian       0.22      0.95      0.36       398\\n      talk.politics.guns       0.59      0.59      0.59       364\\n   talk.politics.mideast       0.85      0.70      0.77       376\\n      talk.politics.misc       0.81      0.08      0.15       310\\n      talk.religion.misc       0.50      0.00      0.01       251\\n\\n                accuracy                           0.61      7532\\n               macro avg       0.72      0.58      0.59      7532\\n            weighted avg       0.72      0.61      0.61      7532\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "classification_report(X_test.target, predictions, target_names=X_test.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}