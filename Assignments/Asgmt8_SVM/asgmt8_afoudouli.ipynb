{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Assignment 8\n",
    "\n",
    "In this assignment, the Credit Card Fraud Detection dataset is used that can be found on [kaggle](https://www.kaggle.com/mlg-ulb/creditcardfraud).\n",
    "\n",
    "In this workbook a classification task to fraudulent and non fraudelent users is done ising support vector machines (SVMs).  \n",
    "Also techniques to handle imbalanced data are implemented."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed install packages uncommenting and executing the following commands\n",
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os \n",
    "\n",
    "os.chdir('C:/Users/anast/OneDrive/Desktop/MSc/MachineLearning/Assignments/Asgmt8_SVM/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'creditcard.csv'\n",
    "\n",
    "data = pd.read_csv(data_file)"
   ]
  },
  {
   "source": [
    "**Scaling**  \n",
    "Time and amount variables need to be scaled. The rest of the variables (the PCs) are already scaled \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data['Amount'] = scaler.fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "data['Time'] = scaler.fit_transform(data['Time'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns='Class')\n",
    "y = data['Class']"
   ]
  },
  {
   "source": [
    "The target variable is extremely imbalanced. Only 0.17% out of all the transactions of the dataset are fraudulent. This problem, may lead any model to overfit the non-fraudulent examples, being unable to recognise fraud. There are different ways to handle such issues.  \n",
    "Here I will experiment with:\n",
    "* Undersampling\n",
    "* Oversampling\n",
    "* Combination of both\n",
    "\n",
    "Some nice guides can be found on [DataCamp](https://www.datacamp.com/community/tutorials/diving-deep-imbalanced-data?utm_source=adwords_ppc&utm_campaignid=898687156&utm_adgroupid=48947256715&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=&utm_creative=332602034349&utm_targetid=aud-390929969673:dsa-429603003980&utm_loc_interest_ms=&utm_loc_physical_ms=9061579&gclid=CjwKCAiAq8f-BRBtEiwAGr3Dgc65y799jXfSyX1UAugegeLHUDk7lb6izpB-coR1udmOQvHoN76s2xoCpg8QAvD_BwE), [KDnuggets](https://www.kdnuggets.com/2020/01/5-most-useful-techniques-handle-imbalanced-datasets.html) and [Machine Learning Mastery](https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Under-sampling\n",
    "\n",
    "**Random under-sampling** \n",
    " \n",
    "In random under-sampling, the only a subset of the majority class examples is retained and all the observation of the minority class are retained.\n",
    "\n",
    "**Pros**: Improve the runtime of the model by reducing the number of training data samples when the training set is gigantic.   \n",
    "**Cons**: There is high risk of information loss as only a small subset of the majority class training examples is used.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fraud = data[data['Class']==1]\n",
    "data_no_fraud = data[data['Class']==0]\n",
    "\n",
    "fraud_count = data_fraud['Class'].count()\n",
    "\n",
    "# undersample majority class\n",
    "data_no_fraud = resample(data_no_fraud, replace=False, n_samples=int(fraud_count*1.75), random_state=909)\n",
    "\n",
    "data_undersampled = pd.concat([data_fraud, data_no_fraud])"
   ]
  },
  {
   "source": [
    "**Tomek Links**  \n",
    "\n",
    "Undersampling can also be achieved using [Tomek links](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.under_sampling.TomekLinks.html). Tomek links are pairs of examples of opposite classes in close vicinity. It is a fairly expensive algorithm since it has to compute pairwise distances between all examples. After this calculation, the majority elements from the Tomek link are removed, thus providing a better decision boundary for a classifier. Samples from the majorith, the minority or both classes can be removed.  \n",
    "Undersampling can also be performed on the resulting dataset as discussed [here](https://www.hilarispublisher.com/open-access/classification-of-imbalance-data-using-tomek-link-tlink-combined-with-random-undersampling-rus-as-a-data-reduction-method-2229-8711-S1111.pdf)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TomekLinks(sampling_strategy='majority')\n",
    "\n",
    "X_tl, y_tl = tl.fit_resample(X,y)"
   ]
  },
  {
   "source": [
    "### Over-sampling\n",
    "\n",
    "**SMOTE**\n",
    "\n",
    "Synthetic Minority Oversampling Technique (SMOTE) is an oversampling technique where the synthetic samples are generated for the minority class. This algorithm helps to overcome the overfitting problem posed by random oversampling. It focuses on the feature space to generate new instances with the help of interpolation between the positive instances that lie together.\n",
    "\n",
    "Specifically, a random example from the minority class is first chosen. Then k of the nearest neighbors for that example are found (typically k=5). A randomly selected neighbor is chosen and a synthetic example is created at a randomly selected point between the two examples in feature space."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(sampling_strategy=0.3, random_state=133, n_jobs=-1)\n",
    "\n",
    "X_sm, y_sm = sm.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}